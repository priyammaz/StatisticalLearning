{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d3935f",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "Name: Priyam Mazumdar\n",
    "\n",
    "NetID: priyamm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67e2d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b011c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Dataset\n",
    "data = pd.read_csv(\"diabetes.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae724fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "# Split data in train and test\n",
    "random.seed(2)\n",
    "\n",
    "index = list(range(len(data)))\n",
    "train_index = random.sample(index, len(index)//2)\n",
    "test_index = [i for i in index if i not in train_index]\n",
    "\n",
    "train_data, test_data = data.iloc[train_index].reset_index(drop=True), data.iloc[test_index].reset_index(drop=True)\n",
    "\n",
    "train_X, train_y = np.array(train_data.drop(columns=\"Outcome\").values), np.array(train_data[\"Outcome\"].values)\n",
    "test_X, test_y = np.array(test_data.drop(columns=\"Outcome\").values), np.array(test_data[\"Outcome\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39208747",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n",
    "Load the Pima Indians Diabetes Database (`PimaIndiansDiabetes`) from the `mlbench` package. If you don't already have this package installed, use the following code. It also randomly splits the data into training and testing. You should preserve this split in the analysis. \n",
    "\n",
    "Read the documentation of this dataset [here](https://cran.r-project.org/web/packages/mlbench/mlbench.pdf) and make sure that you understand the goal of this classification problem. \n",
    "\n",
    "Use a grid of $k$ values (every integer) from 1 to 20. \n",
    "\n",
    "a) [10 pts] Fit a KNN model using `Diab.train` and calculate both training and testing errors. For the testing error, use `Diab.test`. Plot the two errors against the corresponding $k$ values. Make sure that you differentiate them using different colors/shapes and add proper legends. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06f07e",
   "metadata": {},
   "source": [
    "### Problem 1a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6b453ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal K: 7\n",
      "Lowest Testing Error: 0.2344\n"
     ]
    }
   ],
   "source": [
    "train_score = []\n",
    "test_score = []\n",
    "num_iter = 20\n",
    "for k in range(1,num_iter+1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(train_X, train_y)\n",
    "    test_score.append(1 - knn.score(test_X, test_y))\n",
    "    train_score.append(1 - knn.score(train_X, train_y))\n",
    "    \n",
    "plt.plot(range(1,num_iter+1), train_score, label=\"Training Error\")\n",
    "plt.plot(range(1,num_iter+1), test_score, label=\"Testing Error\")\n",
    "plt.xticks(np.arange(1, num_iter+1, 1.0))\n",
    "plt.title(\"Training and Testing Accuracy for KNN\")\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Percent Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "highest_training_score = np.array(test_score).argmin() + 1\n",
    "print(\"Optimal K:\", highest_training_score)\n",
    "print(\"Lowest Testing Error:\", round(train_score[highest_training_score],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101f381",
   "metadata": {},
   "source": [
    "b) [15 pts] Does the plot match (approximately) our intuition of the bias-variance trade-off in terms of having a U-shaped error? What is the optimal $k$ value based on this result? For the optimal `k`, what is the corresponding degrees-of-freedom and its error?\n",
    "\n",
    "**Answer**\n",
    "\n",
    "We see elements of the bias-variance tradeoff, for example when K=1, we can see a very low testing error but a high training error. This is because at K=1, we are able to perfectly reproduce our data, thus giving a low bias, but as we get more data it is unlikely to fall into this perfect reproduction, therefore a high variance. As we increase K we see that our tesing error is starting to decrease, therefore our model is properly generalizing, but as K get even larger, our testing error increases again. This is because a highly paramaterized model is going to have low variance but a high suceptibility to bias.\n",
    "\n",
    "The optimial value for K is 7, as that is when we get our lowest error of 0.2344, and the corresponding degrees of freedom would be 54. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5fff41",
   "metadata": {},
   "source": [
    "c) [15 pts] Suppose we do not have access to `Diab.test` data. Thus, we need to further split the training data into train and validation data to tune `k`. For this question, use the `caret` package to complete the tuning. You are required to \n",
    "   * Train the model with cross-validation using the `train()` function.\n",
    "      * Specify the type of cross-validation using the `trainControl()` function. We need to use three-fold cross-validation.\n",
    "      * Specify a grid of tuning parameters. This can be done using `expand.grid(k = c(1:20))`.\n",
    "   * Report the best parameter with its error. Compare it with your `k` in b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0fd2b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal K: 9\n",
      "Lowest Error: 0.27864583333333337\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_neighbors\": list(range(1,21))}\n",
    "\n",
    "KNN_search_cv = GridSearchCV(KNeighborsClassifier(), \n",
    "                             param_grid=param_grid,\n",
    "                             scoring=\"accuracy\",\n",
    "                             cv=3,\n",
    "                             n_jobs=-1)\n",
    "\n",
    "KNN_search_cv.fit(train_X, train_y)\n",
    "\n",
    "print(\"Optimal K:\", KNN_search_cv.best_params_[\"n_neighbors\"])\n",
    "print(\"Lowest Error:\", 1 - KNN_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b852be2c",
   "metadata": {},
   "source": [
    "When doing a 3-fold cross-validation on only our training data we get the best parameter for the number of neighbors to be 9, with the lowest error of 0.278. This is slightly higher than the K of 7 we got previously, and our error from CV is also slightly higher from 0.2344 on our testing data in the last problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d246f15",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "a. [10 pts] Generate $p=5$ independent standard Normal covariates $X_1, X_2, X_3, X_4, X_5$ of $n = 1000$ independent observations. Then, generate $Y$ from the regression model\n",
    "  $$ Y = X_1 + 0.5 \\times X_2 - X_3 + \\epsilon,$$\n",
    "with i.i.d. standard normal error $\\epsilon$. Make sure to set a random seed 1 for reproducibility. \n",
    "\n",
    " - Use a KNN implementation from an existing package. Report the mean squared error (MSE) for your prediction with `k = 5`. Use the first 500 observations as the training data and the rest as testing data. Predict the $Y$ values using your KNN function with `k = 5`. Mean squared error is \n",
    "  $$\\frac{1}{N}\\sum_i (y_i - \\widehat y_i)^2$$ This question also helps you validate your own function in b). a) and b) are expected have similar (possibly not identical) results.\n",
    "  - Hints: this is a **regression** problem instead of a classification one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e74d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "X_data = np.random.standard_normal(size=(1000,5))\n",
    "linear_transformation = np.array([1, 0.5, -1, 0, 0]).reshape(5,1)\n",
    "Y_data = X_data.dot(linear_transformation) + np.random.standard_normal(size=(1000,1))\n",
    "\n",
    "train_X, train_y = X_data[:500], Y_data[:500]\n",
    "test_X, test_y = X_data[500:], Y_data[500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66bf01b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.3296005985016977\n"
     ]
    }
   ],
   "source": [
    "knnreg = KNeighborsRegressor(n_neighbors = 5, metric='euclidean')\n",
    "knnreg.fit(train_X, train_y)\n",
    "\n",
    "print(\"Mean Squared Error:\",mean_squared_error(knnreg.predict(test_X), test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3fa0fe",
   "metadata": {},
   "source": [
    "b. [30 pts] For this question, you __cannot__ use (load) any additional `R` package. Write your own function `myknn(xtrain, ytrain, xtest, k)` that fits a KNN model and predict multiple target points `xtest`. The function should return a variable `ytest`.\n",
    "    - Here, `xtrain` is the training dataset covariate value, `ytrain` is the training data outcome, and `k` is the number of nearest neighbors. `ytest` is the prediction on `xtest`. \n",
    "    - Use Euclidean distance to calculate the closeness between two points.\n",
    "    - Test your code by reporting the mean square error on the testing data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b17712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.3296005985016977\n"
     ]
    }
   ],
   "source": [
    "class KNNRegressor:\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        \n",
    "    def fit(self,x,y):\n",
    "        \"\"\"\n",
    "        Store training data to compare to during predictions\n",
    "        \"\"\"\n",
    "        self.train_x = x\n",
    "        self.train_y = y\n",
    "    \n",
    "    def predict(self,x):\n",
    "        \"\"\"\n",
    "        Loop through all available test data and generate predictions\n",
    "        \"\"\"\n",
    "        predictions_list = []\n",
    "        for test in x:\n",
    "            predictions_list.append(self.predict_single_sample(test))\n",
    "        return np.array(predictions_list).reshape(-1, 1)\n",
    "    \n",
    "    def predict_single_sample(self, x):\n",
    "        \"\"\"\n",
    "        For a single sample calculate the euclidian distance and averaget the n closest points\n",
    "        \"\"\"\n",
    "        distance_list = []\n",
    "        for train in self.train_x:\n",
    "            distance_list.append(self.euclidian_distance(train, x))\n",
    "        distance_list = np.array(distance_list)\n",
    "        indicies = distance_list.argsort()[:self.n_neighbors]\n",
    "        prediction = self.train_y[indicies].mean()\n",
    "        return prediction\n",
    "    \n",
    "    def mse_score(self,x,y):\n",
    "        \"\"\"\n",
    "        Calculate the mean squared error of a set of samples\n",
    "        \"\"\"\n",
    "        predictions = self.predict(x)\n",
    "        return np.sum((predictions - y)**2) / len(predictions)\n",
    "        \n",
    "    def euclidian_distance(self,train, x):\n",
    "        return np.sum((train - x)**2)**0.5\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "knn = KNNRegressor(n_neighbors=5)\n",
    "knn.fit(train_X, train_y)\n",
    "\n",
    "print(\"Mean Squared Error:\",knn.mse_score(test_X, test_y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16fefd",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Let's consider a high-dimensional setting. Keep the data-generating model the same as question 2. In addition to the outcomes and covariates from question 2, we will also generate 95 more noisy variables to make p = 100. In this question, you can use a KNN function from any existing package. \n",
    "\n",
    "We consider two different settings to generate that additional set of 95 covariates. Make sure to set random seeds for reproducibility. \n",
    "\n",
    "  * Generate another 95-dimensional covariates with all independent standard Gaussian entries.\n",
    "  * Generate another 95-dimensional covariates using the formula $X^T A$, where $X$ is the original 5-dimensional vector, and $A$ is a $5 \\times 95$ dimensional (fixed) matrix that remains the same for all observations. You should generate $A$ just once using i.i.d. uniform $[0, 1]$ entries and then apply $A$ to your current 5-dimensional data. \n",
    "\n",
    "Fit KNN in both settings (with the total of 100 covariates) and select the best $k$ value. Answer the following questions\n",
    "\n",
    "  a) [10 pts] For the first setting, what is the best $k$ and the best mean squared error for prediction?\n",
    "  \n",
    "  b) [10 pts] For the second setting, what is the best $k$ and the best mean squared error for prediction?\n",
    "  \n",
    "  c) [10 pts] In which setting $k$NN performs better? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a04ad511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First Settings ---\n",
      "Optimal K: 13\n",
      "Lowest Error: 2.411872848822325\n",
      "--- Second Settings ---\n",
      "Optimal K: 7\n",
      "Lowest Error: 1.5471072743000391\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "# a) First Setting Data Gen\n",
    "first_setting_gen_data = np.random.standard_normal(size=(1000,95))\n",
    "first_setting_gen_data = np.concatenate((X_data, first_setting_gen_data), axis=1)\n",
    "first_settings_train, first_settings_test = first_setting_gen_data[:500], first_setting_gen_data[500:]\n",
    "lowest_error = np.inf \n",
    "optimal_first_k = 0\n",
    "for i in range(1,100):\n",
    "    knnreg = KNeighborsRegressor(n_neighbors = i, metric='euclidean')\n",
    "    knnreg.fit(first_settings_train, train_y)\n",
    "    mse = mean_squared_error(knnreg.predict(first_settings_test), test_y)\n",
    "    if mse < lowest_error:\n",
    "        lowest_error = mse\n",
    "        optimal_first_k = i\n",
    "        \n",
    "print(\"--- First Settings ---\")\n",
    "print(\"Optimal K:\",optimal_first_k)\n",
    "print(\"Lowest Error:\", lowest_error)\n",
    "\n",
    "\n",
    "\n",
    "# b) Second Setting Data Gen\n",
    "A = np.random.uniform(size=(5,95))\n",
    "second_setting_gen_data = np.concatenate((X_data, X_data.dot(A)), axis=1)\n",
    "second_settings_train, second_settings_test = second_setting_gen_data[:500], second_setting_gen_data[500:]\n",
    "\n",
    "lowest_error = np.inf \n",
    "optimal_second_k = 0\n",
    "for i in range(1,100):\n",
    "    knnreg = KNeighborsRegressor(n_neighbors = i, metric='euclidean')\n",
    "    knnreg.fit(second_settings_train, train_y)\n",
    "    mse = mean_squared_error(knnreg.predict(second_settings_test), test_y)\n",
    "    if mse < lowest_error:\n",
    "        lowest_error = mse\n",
    "        optimal_second_k = i\n",
    "        \n",
    "print(\"--- Second Settings ---\")\n",
    "print(\"Optimal K:\",optimal_second_k)\n",
    "print(\"Lowest Error:\", lowest_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc37b1b",
   "metadata": {},
   "source": [
    "### Answer\n",
    "I found that our KNN for the second setting yielded better performance with a lower error. The reason for this is because in the first setting we added purely random noise to our data, thus clouding the underlying relationships between predictors. On the other hand, in the second setting we generated random uniform data but applied a transformation to it from our original 5 predictors, which in turn has made the uniform data produced more in line with the original data. The original data was also used to generate our Y target, so it makes sense that the 100 predictors that flollow the patterns of our original dataset performs better. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
